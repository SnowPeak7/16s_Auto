Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 8
Rules claiming more threads will be scaled down.
Job stats:
job             count
------------  -------
all                 1
qiime_import        1
total               2

Select jobs to execute...

[Thu Aug  3 17:59:41 2023]
rule qiime_import:
    input: 02.clean_fastq/filelist.txt
    output: 03.import/reads.qza
    jobid: 6
    reason: Missing output files: 03.import/reads.qza
    resources: tmpdir=/tmp

[Thu Aug  3 17:59:41 2023]
Error in rule qiime_import:
    jobid: 6
    input: 02.clean_fastq/filelist.txt
    output: 03.import/reads.qza
    shell:
        
        qiime tools import                  --type 'SampleData[PairedEndSequencesWithQuality]'                  --input-path 02.clean_fastq/filelist.txt                  --output-path 03.import/reads.qza                  --input-format SingleEndFastqManifestPhred33
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2023-08-03T175941.679657.snakemake.log
